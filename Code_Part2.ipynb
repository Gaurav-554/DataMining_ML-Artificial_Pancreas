{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below section reads all the required data and generates a combined Data-Time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "InsulinData_Patient1 = pd.read_csv(\"dataset/InsulinData_Patient1.csv\")\n",
    "InsulinData_Patient1[\"combinedStamp\"] = pd.to_datetime(InsulinData_Patient1[\"Date\"] + ' - ' + InsulinData_Patient1[\"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CGMData_Patient1 = pd.read_csv(\"dataset/CGMData_Patient1.csv\")\n",
    "CGMData_Patient1[\"combinedStamp\"] = pd.to_datetime(CGMData_Patient1[\"Date\"] + ' - ' + CGMData_Patient1[\"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "InsulinData_Patient2 = pd.read_csv(\"dataset/InsulinData_Patient2.csv\")\n",
    "InsulinData_Patient2[\"combinedStamp\"] = pd.to_datetime(InsulinData_Patient2[\"Date\"] + ' - ' + InsulinData_Patient2[\"Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CGMData_Patient2 = pd.read_csv(\"dataset/CGMData_Patient2.csv\")\n",
    "CGMData_Patient2[\"combinedStamp\"] = pd.to_datetime(CGMData_Patient2[\"Date\"] + ' - ' + CGMData_Patient2[\"Time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below function extracts Meal Data as follows:\n",
    "Start of a meal can be obtained from InsulinData_Patient#.csv. Search column Y for a non NAN non zero value. This time indicates the start of a meal (tm). \n",
    "\n",
    "There can be three conditions:\n",
    "1. There is no meal from time tm to time tm+2hrs. Then use this stretch as meal data.\n",
    "2. There is a meal at some time tp in between tp>tm and tp< tm+2hrs. Ignore the meal data at time tm and consider the meal at time tp instead.\n",
    "3. There is a meal at time tm+2hrs, then consider the stretch from tm+1hr 30min to tm+4hrs as meal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractMealData(cgm, insulin):\n",
    "    meal = insulin.sort_values(by = \"combinedStamp\")\n",
    "\n",
    "    meal = meal[~pd.isnull(meal[\"BWZ Carb Input (grams)\"]) & meal[\"BWZ Carb Input (grams)\"] != 0.0]\n",
    "\n",
    "    lst1 = []\n",
    "    diff = 0\n",
    "    meal.reset_index(drop = True, inplace = True)\n",
    "    for index, item in enumerate(meal[\"combinedStamp\"]):\n",
    "        if index < len(meal[\"combinedStamp\"]) - 1:\n",
    "            diff = (meal[\"combinedStamp\"][index + 1] - item).seconds\n",
    "            if diff > 2 * 60 * 60:\n",
    "                lst1.append(item)\n",
    "            if diff < 2 * 60 * 60:\n",
    "                lst1.append(meal[\"combinedStamp\"][index + 1])\n",
    "            if diff == 2 * 60 * 60:\n",
    "                lst1.append(meal[\"combinedStamp\"][index + 1])\n",
    "    lst1 = list(set(lst1))\n",
    "\n",
    "    lst2 = []\n",
    "    cgm = cgm.set_index(pd.DatetimeIndex(cgm[\"combinedStamp\"]))\n",
    "    for _, item in enumerate(lst1):\n",
    "        date = item.date().strftime(\"%m/%d/%Y\")\n",
    "        endTime = (pd.to_datetime(item + timedelta(minutes = 120))).strftime('%H:%M:%S')\n",
    "        startTime = (pd.to_datetime(item - timedelta(minutes = 30))).strftime('%H:%M:%S')\n",
    "        temp = cgm.loc[cgm[\"Date\"] == date].between_time(startTime, endTime)[\"Sensor Glucose (mg/dL)\"]\n",
    "        lst2.append(temp.values.tolist())\n",
    "\n",
    "    mealData = pd.DataFrame(lst2)\n",
    "    return mealData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below function extracts Meal Data as follows:\n",
    "No meal data comprises 2 hrs of raw data that does not have meal intake.\n",
    "\n",
    "Start of no meal is at time tm+2hrs where tm is the start of some meal. We need to obtain a 2 hr stretch of no meal time. So you need to find all 2 hr stretches in a day that have no meal and do not fall within 2 hrs of the start of a meal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNoMealData(cgm, insulin):\n",
    "    nomeal = insulin.sort_values(by = \"combinedStamp\")\n",
    "\n",
    "    nomeal = nomeal[~pd.isnull(nomeal[\"BWZ Carb Input (grams)\"]) & nomeal[\"BWZ Carb Input (grams)\"] != 0.0]\n",
    "\n",
    "    lst1 = []\n",
    "    val = 0\n",
    "    nomeal.reset_index(drop = True, inplace = True)\n",
    "    for index, item in enumerate(nomeal[\"combinedStamp\"]):\n",
    "        if index < len(nomeal[\"combinedStamp\"]) - 1:\n",
    "            val = (nomeal[\"combinedStamp\"][index + 1] - item).seconds\n",
    "            if val >= 4 * 60 * 60:\n",
    "                lst1.append(item + pd.Timedelta(hours=2))\n",
    "    lst1 = list(set(lst1))\n",
    "\n",
    "    lst2 = []\n",
    "    cgm = cgm.set_index(pd.DatetimeIndex(cgm[\"combinedStamp\"]))\n",
    "    for _, item in enumerate(lst1):\n",
    "        date = item.date().strftime(\"%m/%d/%Y\")\n",
    "        endTime = (pd.to_datetime(item + timedelta(minutes = 120))).strftime('%H:%M:%S')\n",
    "        startTime = (pd.to_datetime(item)).strftime('%H:%M:%S')\n",
    "        temp = cgm.loc[cgm[\"Date\"] == date].between_time(startTime, endTime)[\"Sensor Glucose (mg/dL)\"]\n",
    "        lst2.append(temp.values.tolist())\n",
    "\n",
    "    nomealData = pd.DataFrame(lst2)\n",
    "    return nomealData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below function cleans the data by:\n",
    "1. Deleting all observations with more than or equal to 50% missing values\n",
    "2. Trims the data to a common shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(data):\n",
    "    _, columns = data.shape\n",
    "    thresh = columns * 0.5\n",
    "    data = data.dropna(thresh = thresh)\n",
    "    data = data.iloc[:, 0:24]\n",
    "    data.reset_index(drop = True, inplace = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Dataset is created below by:\n",
    "1. Labeling data as meal or no-meal instances (meal=1 and no-meal=0)\n",
    "2. Merging all the data while shuffling\n",
    "3. Replacing remaining NaN values with column Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mealData_Patient1 = extractMealData(CGMData_Patient1, InsulinData_Patient1)\n",
    "mealData_Patient1 = cleanData(mealData_Patient1)\n",
    "mealData_Patient1[\"lbl\"] = 1\n",
    "\n",
    "nomealData_Patient1 = extractNoMealData(CGMData_Patient1, InsulinData_Patient1)\n",
    "nomealData_Patient1 = cleanData(nomealData_Patient1)\n",
    "nomealData_Patient1[\"lbl\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mealData_Patient2 = extractMealData(CGMData_Patient2, InsulinData_Patient2)\n",
    "mealData_Patient2 = cleanData(mealData_Patient2)\n",
    "mealData_Patient2[\"lbl\"] = 1\n",
    "\n",
    "nomealData_Patient2 = extractNoMealData(CGMData_Patient2, InsulinData_Patient2)\n",
    "nomealData_Patient2 = cleanData(nomealData_Patient2)\n",
    "nomealData_Patient2[\"lbl\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = shuffle(pd.concat([nomealData_Patient1, mealData_Patient1, nomealData_Patient2, mealData_Patient2]), random_state = 5)\n",
    "finalData = finalData.reset_index(drop = True)\n",
    "\n",
    "for column in finalData.columns:\n",
    "    finalData[column].fillna(finalData[column].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction\n",
    "\n",
    "transform = list()\n",
    "transform.append(('mms', MinMaxScaler()))\n",
    "transform.append(('ss', StandardScaler()))\n",
    "transform.append(('rs', RobustScaler()))\n",
    "transform.append(('qt', QuantileTransformer(n_quantiles = 100, output_distribution = \"normal\")))\n",
    "transform.append(('kbd', KBinsDiscretizer(n_bins = 10, encode = \"ordinal\", strategy = \"uniform\")))\n",
    "transform.append(('pca', PCA(n_components = 7)))\n",
    "transform.append(('svd', TruncatedSVD(n_components = 7)))\n",
    "\n",
    "feature_union = FeatureUnion(transform)\n",
    "\n",
    "\n",
    "## Selection\n",
    "# Selecting top 15 features\n",
    "\n",
    "rfe = RFE(estimator = RandomForestClassifier(max_depth = 10, random_state = 5), n_features_to_select = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the created pipeline and reporting cross validation results\n",
    "Model used -> Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66 accuracy with a standard deviation of 0.03\n"
     ]
    }
   ],
   "source": [
    "y = finalData[\"lbl\"]\n",
    "X = finalData.drop(columns = \"lbl\")\n",
    "\n",
    "model = RandomForestClassifier(max_depth = 10, random_state = 5)\n",
    "\n",
    "\n",
    "steps = list()\n",
    "steps.append(('fu', feature_union))\n",
    "steps.append(('rfe', rfe))\n",
    "steps.append(('m', model))\n",
    "pipeline = Pipeline(steps = steps)\n",
    "\n",
    "scores = cross_val_score(pipeline, X, y, cv = 5)\n",
    "    \n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
